apiVersion: batch/v1
kind: Job
metadata:
  name: ddp-1node
  namespace: ai-lab
  labels:
    app: ddp-training
    type: single-node
spec:
  backoffLimit: 0
  template:
    metadata:
      labels:
        job-name: ddp-1node
    spec:
      restartPolicy: Never
      containers:
      - name: trainer
        image: nvcr.io/nvidia/pytorch:24.03-py3
        imagePullPolicy: IfNotPresent
        resources:
          limits:
            nvidia.com/gpu: 4  # Adjust based on your node's GPU count
          requests:
            nvidia.com/gpu: 4
        env:
        - name: NCCL_ASYNC_ERROR_HANDLING
          value: "1"
        - name: NCCL_IB_DISABLE
          value: "1"
        - name: OMP_NUM_THREADS
          value: "4"
        - name: PYTHONUNBUFFERED
          value: "1"
        volumeMounts:
        - name: script
          mountPath: /workspace/train.py
          subPath: train.py
        - name: outputs
          mountPath: /outputs
        command: ["bash", "-lc"]
        args:
        - |
          cd /workspace && \
          torchrun --standalone --nproc_per_node=4 \
            /workspace/train.py --epochs 2 --batch-size 256 --out-dir /outputs
      volumes:
      - name: script
        configMap:
          name: ddp-train
      - name: outputs
        emptyDir: {}